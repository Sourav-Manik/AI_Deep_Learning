{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOLueZTtxF545HkbYDqtU1m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sourav-Manik/AI_Deep_Learning/blob/main/Language_Modelling_Next_Word_Prediction_(Customized_Dataset).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Import Necessary libraries##"
      ],
      "metadata": {
        "id": "ZxKyE2TYdgeA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "Rt-TehbZdmK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Import Data##"
      ],
      "metadata": {
        "id": "WPOiawT5dy9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_data = \"\"\"Artificial Intelligence Program is really going good.\\n\n",
        "My learners are giving their best efforts and time in completing the task at the given time./n\n",
        "I completely trust my learners that they will defenitely with their hard work reach their goal.\\n\n",
        "As long as, you keep regular practise with perserverance and with patiency, we can achieve what we want.\"\"\"\n",
        "my_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "VKQUOEf1d2kB",
        "outputId": "3b625e91-852a-43b1-ca89-dacc20a9b261"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Artificial Intelligence Program is really going good.\\n\\nMy learners are giving their best efforts and time in completing the task at the given time./n\\nI completely trust my learners that they will defenitely with their hard work reach their goal.\\n\\nAs long as, you keep regular practise with perserverance and with patiency, we can achieve what we want.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Data Preparation##"
      ],
      "metadata": {
        "id": "87r8nW8FgtFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([my_data])\n",
        "encoded_data = tokenizer.texts_to_sequences(texts = [my_data])[0]"
      ],
      "metadata": {
        "id": "P5rD6OgJgxxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min(encoded_data), max(encoded_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IP2JbIcegx1o",
        "outputId": "74b4b5a1-d982-4034-c8e4-a5f55bf1c54a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 48)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = len(set(encoded_data)) #getting unique value by using sets\n",
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pM3M48DEhgV4",
        "outputId": "855589ec-84a7-4962-e016-f77b366dd891"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.1 Create sequence of words to fit the model with one as input and one word as output.###"
      ],
      "metadata": {
        "id": "tjRscOb8htTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(encoded_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3qBsFnwhqaJ",
        "outputId": "c897fcb5-ad78-4548-9314-45d4396bf1ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = []\n",
        "\n",
        "for i in range(1,len(encoded_data)):\n",
        "  sequence = encoded_data[i-1:i+1]\n",
        "  sequences.append(sequence)\n",
        "print('Total number of sequences : ',len(sequences))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-Z6G1tHjK2-",
        "outputId": "2780054e-9195-4ffd-85d1-e5e8dbad8634"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of sequences :  58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Split the Sequences into Training and Test"
      ],
      "metadata": {
        "id": "wAUA0svkjLNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "sequences = np.array(sequences)\n",
        "X = sequences[:,0] #taking only input data\n",
        "y = sequences[:,1]"
      ],
      "metadata": {
        "id": "3uqLH67XkFo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKurN4tpkFze",
        "outputId": "562d6dae-4318-4d62-c345-20983ef8423c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([10, 11, 12, 13, 14])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0WtHnAkkgta",
        "outputId": "fa8c9a51-2304-40f8-ae7f-880b7ae89162"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([11, 12, 13, 14, 15])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4. Model Building##"
      ],
      "metadata": {
        "id": "O6VF2X5pkofc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = vocab + 1 # we have to add 1 as it is required for below.\n",
        "model =Sequential()\n",
        "model.add(Embedding(input_dim=vocab,output_dim = 40,input_length=1)) #output dimension is set as 10. It means that for 1 input it will have 10 embeddings\n",
        "model.add(LSTM(units = 50,dropout = 0.15))\n",
        "model.add(Dense(units=50, activation = 'tanh'))\n",
        "model.add(Dropout(0.40))\n",
        "model.add(Dense(units = vocab,activation = 'softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZV3TcBLdleyj",
        "outputId": "a983eeed-4db2-4840-ec58-acca65bdd31b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 1, 40)             1960      \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 50)                18200     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 50)                2550      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 50)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 49)                2499      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,209\n",
            "Trainable params: 25,209\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='Adam', loss ='sparse_categorical_crossentropy' ,metrics = 'accuracy')"
      ],
      "metadata": {
        "id": "-YOVLSp6le1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5. Model Training##"
      ],
      "metadata": {
        "id": "2GdbNS17n4MZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=X,y=y,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibbDS5-yn9dd",
        "outputId": "c8398866-f31f-4147-90fe-e0318a3d33e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 7s 17ms/step - loss: 3.8946 - accuracy: 0.0172\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 3.8905 - accuracy: 0.0690\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 3.8886 - accuracy: 0.0862\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 3.8867 - accuracy: 0.1034\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 3.8848 - accuracy: 0.1034\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 3.8825 - accuracy: 0.1207\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 3.8809 - accuracy: 0.0690\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 3.8764 - accuracy: 0.1207\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 3.8764 - accuracy: 0.1034\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 3.8754 - accuracy: 0.1034\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 3.8712 - accuracy: 0.1207\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 3.8681 - accuracy: 0.0690\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 3.8696 - accuracy: 0.1034\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 3.8653 - accuracy: 0.1552\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 3.8612 - accuracy: 0.1207\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 3.8590 - accuracy: 0.1207\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 3.8539 - accuracy: 0.1207\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 3.8507 - accuracy: 0.0862\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 3.8473 - accuracy: 0.1207\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 3.8446 - accuracy: 0.1207\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 3.8403 - accuracy: 0.1207\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 3.8335 - accuracy: 0.1207\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 3.8279 - accuracy: 0.1034\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 3.8239 - accuracy: 0.1379\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 3.8152 - accuracy: 0.1207\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 3.8084 - accuracy: 0.1034\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 3.8071 - accuracy: 0.1552\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 3.7969 - accuracy: 0.1034\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 3.7913 - accuracy: 0.1034\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 3.7790 - accuracy: 0.1207\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 3.7728 - accuracy: 0.1379\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 3.7509 - accuracy: 0.1034\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 3.7453 - accuracy: 0.1379\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 3.7397 - accuracy: 0.1034\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 3.7224 - accuracy: 0.1897\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 3.6950 - accuracy: 0.1379\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 3.6800 - accuracy: 0.1379\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 3.6612 - accuracy: 0.1379\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 3.6629 - accuracy: 0.0690\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 3.6186 - accuracy: 0.1552\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 3.6046 - accuracy: 0.1207\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 3.5781 - accuracy: 0.1379\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 3.5671 - accuracy: 0.1379\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 3.5172 - accuracy: 0.1379\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 3.5005 - accuracy: 0.1552\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 3.4536 - accuracy: 0.1552\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 3.3991 - accuracy: 0.1379\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 3.3730 - accuracy: 0.1207\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 3.3530 - accuracy: 0.1207\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 3.3067 - accuracy: 0.1552\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 3.2892 - accuracy: 0.1724\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 3.2387 - accuracy: 0.2241\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 3.2073 - accuracy: 0.1552\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 3.1496 - accuracy: 0.1379\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 3.1183 - accuracy: 0.1552\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 3.0522 - accuracy: 0.1379\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 3.0578 - accuracy: 0.1724\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 3.0008 - accuracy: 0.1379\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.9026 - accuracy: 0.2241\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 2.9050 - accuracy: 0.1897\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 2.9164 - accuracy: 0.1897\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.8506 - accuracy: 0.2241\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 2.8331 - accuracy: 0.1897\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.8048 - accuracy: 0.2414\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.7638 - accuracy: 0.2931\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 2.7345 - accuracy: 0.2586\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 2.7562 - accuracy: 0.2241\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 2.6697 - accuracy: 0.2931\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 2.5919 - accuracy: 0.3276\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 2.6082 - accuracy: 0.2414\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 2.5576 - accuracy: 0.3966\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 2.5545 - accuracy: 0.2586\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 2.4756 - accuracy: 0.3276\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 2.3778 - accuracy: 0.3448\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 2.4072 - accuracy: 0.3448\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 2.3345 - accuracy: 0.4138\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.3411 - accuracy: 0.3793\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 2.2501 - accuracy: 0.4138\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 2.2691 - accuracy: 0.3621\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 2.1018 - accuracy: 0.5345\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 2.1712 - accuracy: 0.3621\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 2.2030 - accuracy: 0.4138\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 2.1149 - accuracy: 0.3966\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 2.0870 - accuracy: 0.5000\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 2.1158 - accuracy: 0.3966\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 2.0092 - accuracy: 0.4483\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1.9447 - accuracy: 0.5690\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.9688 - accuracy: 0.4483\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 2.0265 - accuracy: 0.3621\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.9869 - accuracy: 0.4655\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 1.8685 - accuracy: 0.4828\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 1.8926 - accuracy: 0.4310\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.7862 - accuracy: 0.6207\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.7633 - accuracy: 0.5690\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1.7235 - accuracy: 0.5862\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.7119 - accuracy: 0.6034\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 1.7854 - accuracy: 0.5862\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 1.6561 - accuracy: 0.6034\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 1.6790 - accuracy: 0.5862\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 1.7202 - accuracy: 0.5690\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdabf2f0f90>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6. Model Prediction##"
      ],
      "metadata": {
        "id": "lDcS29BQoHUv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate new words based on the previous word"
      ],
      "metadata": {
        "id": "W58wI7DssgXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index.items()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfY9GlKxsobH",
        "outputId": "7ea83951-e0ce-4994-92c9-98b2853355ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_items([('their', 1), ('with', 2), ('my', 3), ('learners', 4), ('and', 5), ('time', 6), ('the', 7), ('as', 8), ('we', 9), ('artificial', 10), ('intelligence', 11), ('program', 12), ('is', 13), ('really', 14), ('going', 15), ('good', 16), ('are', 17), ('giving', 18), ('best', 19), ('efforts', 20), ('in', 21), ('completing', 22), ('task', 23), ('at', 24), ('given', 25), ('n', 26), ('i', 27), ('completely', 28), ('trust', 29), ('that', 30), ('they', 31), ('will', 32), ('defenitely', 33), ('hard', 34), ('work', 35), ('reach', 36), ('goal', 37), ('long', 38), ('you', 39), ('keep', 40), ('regular', 41), ('practise', 42), ('perserverance', 43), ('patiency', 44), ('can', 45), ('achieve', 46), ('what', 47), ('want', 48)])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from numpy.core.multiarray import result_type\n",
        "def generate_text_sequence(model,tokenizer,enter_text,n_pred):\n",
        "  in_text, result = enter_text,enter_text\n",
        "\n",
        "  for _ in range(n_pred):\n",
        "      encoded_data = tokenizer.texts_to_sequences(texts = [my_data])[0]\n",
        "      encoded_data = np.array(encoded_data)\n",
        "\n",
        "      y_pred = model.predict(encoded_data)\n",
        "\n",
        "      #mapping the predicted word index to the word\n",
        "      predicted_word = ''\n",
        "      for word,index in tokenizer.word_index.items():\n",
        "        if index == y_pred.all():\n",
        "           predicted_word = word\n",
        "           break\n",
        "\n",
        "      in_text, result =predicted_word, result + '' + predicted_word\n",
        "  return result"
      ],
      "metadata": {
        "id": "8fwEfnixsoeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text_sequence(model,tokenizer, 'learners',2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "6a0kN4OQt-7Q",
        "outputId": "48779981-6b4f-4b41-e1da-c4e9b8e91495"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 1s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'learnerstheirtheir'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HOxBrQaf5_in"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}