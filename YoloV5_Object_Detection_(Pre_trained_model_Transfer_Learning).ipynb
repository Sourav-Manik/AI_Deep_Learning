{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1BwWZncg5eGd_-Ng2mGgP3f5wr5-bD6SQ",
      "authorship_tag": "ABX9TyNgURQZJJgU0mWof7ZY/uaB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sourav-Manik/AI_Deep_Learning/blob/main/YoloV5_Object_Detection_(Pre_trained_model_Transfer_Learning).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 1: Cloning the github repository of YoloV5"
      ],
      "metadata": {
        "id": "xvV5rFgxtUhZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5"
      ],
      "metadata": {
        "id": "JaVl7Ijstc25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "671dcc9d-434f-4448-c7b5-cc8b0ee474ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 14887, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 14887 (delta 0), reused 0 (delta 0), pack-reused 14882\u001b[K\n",
            "Receiving objects: 100% (14887/14887), 13.91 MiB | 17.54 MiB/s, done.\n",
            "Resolving deltas: 100% (10248/10248), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcTRYnPFtc7x",
        "outputId": "a46ac05b-fbc1-41c9-a401-6c742a8e6708"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Update the current Directory to yolov5"
      ],
      "metadata": {
        "id": "FRDQI7OEtnwi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/yolov5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25UJi8NztdAz",
        "outputId": "37d13f6e-9fd9-462c-f7d7-601c99eebcbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 3: Install the dependencies/requirements"
      ],
      "metadata": {
        "id": "JPlKsHIbt4SJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "Um2qIxLRtdGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Run Object Detection on Images. Provide the Image Path"
      ],
      "metadata": {
        "id": "9SMYEsj_9Sra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image File"
      ],
      "metadata": {
        "id": "GGzheCIAAmJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --source /content/yolov5/data/images/bus.jpg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hys9Y96WtdDg",
        "outputId": "047acc57-a67c-4781-e7ae-2b599d08739e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=yolov5s.pt, source=/content/yolov5/data/images/bus.jpg, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 ðŸš€ v7.0-49-g3c1afd9 Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
            "100% 14.1M/14.1M [00:00<00:00, 16.0MB/s]\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
            "image 1/1 /content/yolov5/data/images/bus.jpg: 640x480 4 persons, 1 bus, 17.3ms\n",
            "Speed: 0.6ms pre-process, 17.3ms inference, 37.7ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/exp\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Video File"
      ],
      "metadata": {
        "id": "yzhYY0BD9rSz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --source /content/yolov5/data/Videos/Moving_Cars.mp4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hx9N9LjstdIp",
        "outputId": "34b13158-40c4-4eed-c04c-7f5700a48f7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=yolov5s.pt, source=/content/yolov5/data/Videos/Moving_Cars.mp4, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 ðŸš€ v7.0-49-g3c1afd9 Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
            "Traceback (most recent call last):\n",
            "  File \"detect.py\", line 261, in <module>\n",
            "    main(opt)\n",
            "  File \"detect.py\", line 256, in main\n",
            "    run(**vars(opt))\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"detect.py\", line 111, in run\n",
            "    dataset = LoadImages(source, img_size=imgsz, stride=stride, auto=pt, vid_stride=vid_stride)\n",
            "  File \"/content/yolov5/utils/dataloaders.py\", line 254, in __init__\n",
            "    raise FileNotFoundError(f'{p} does not exist')\n",
            "FileNotFoundError: /content/yolov5/data/Videos/Moving_Cars.mp4 does not exist\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#End"
      ],
      "metadata": {
        "id": "4tcd-RyXAq3q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}